\label{chap:background}

    This chapter discusses relevant background information toward the goal of implementing a packetized display protocol (PDP) architecture for Infrared Scene Projector systems (IRSPs). First, it gives an overview of what constitutes an IRSP system. Following this, it provides a general discussion of how common display protocols work to send pixel data to a display system (e.g. a television). Finally, it discusses how these protocols are utilized within an IRLED project system including discussion of example scenarios.

\section{IRLED Projector Systems}

    \begin{figure}
        \centering
        \includegraphics[width=1.0\textwidth]{fig/sleds_system.pdf}
        \caption{IRLED Scene Projector System}
        \label{fig:sleds_system}
    \end{figure}

    IRLED based IRSPs are made up light emitting diodes (LEDs) that emit light in the IR spectrum\cite{biard1966semiconductor}. Since their inception they have been utilized in various fields such as medical\cite{MonteiroEtAl2011,MEEKS1998433,Sadick2009,takhtfooladi2015effects,yamanishi1995respiration} sensing; tracking; and localization\cite{PlotogVladescu2015,Kimon2001,SCHOLZ20151233,WalshDaemsSteckel2015,zeylikovich2003mid}, and communication\cite{CossuEtAl2014,escobosa2004ir,GeorgopoulosKormakopoulos1986,sohn2007localization,JangEtAl2012}. Modern IRLED projectors are an emerging technology with various applications within the IR sensor testing community. A complete IRLED based IRSP system consist of various technologies and processes as shown in Figure~\ref{fig:sleds_system}. One denotes the scene generation and non-uniformity correction (NUC) process. This is where pixel data representing IR scenes is fed to a system for display. The NUC process is for correcting for physical and thermal non-uniformity\cite{BarakhshanEtAl2017} in an IRLED array\cite{BarakhshanEtAl2018}. Two denotes the close support electronics\cite{ejzak4} which are responsible for converting a digital representation of a scene into analog signaling that goes directly to an array. Three indicates the dewar\cite{lang1, MarksEtAl2017} or vaccum chamber which houses an IRLED array and is utilized to keep it below ambient temperatures or at cryogenic temperature ranges. Four indicates an IRLED hybrid which consist of a Read-in Integrated Circuit (RIIC)\cite{HernandezEtAl2017} used to address an IRLED array and the array itself. Analog signals coming from the CSE go into the dewar, and then are mapped using the RIIC, which results in specific IRLEDs within an array being driven. Five indicates an IR recording apparatus of some sort utilized to record IR data from an array. Synchronization between source generation, display, and recording is maintained via synchronization signaling. Often Camera Link serial communication\cite{CameraLink2000, zhu2008design} is used.


    Figure~\ref{fig:sleds_timeline} shows the development timeline for IRLED Projector technology. In 2008, the world's first IRLED array called the Superlattice Light Emitting Diodes (SLEDs) array was completed in 2008\cite{ahmed1}. This device was a hybridized combination of an 68 by 68 IRLED wafer bonded to a RIIC wafer\cite{das2} providing the electronics to drive the array. Initial testing was done by hand prior the design and implementation of the overall drive system was completed in 2011. Following this, an increased IRLED wafer of 512x512 size was fabricated in 2014\cite{norton1}. These efforts culminated in the first two IRLED projector systems in 2016. The first, TCSA (Two Color SLEDS Array), a 512 by 512 sized array\cite{McGeeEtAl2015, ejzak1, ejzak2, EjzakEtAl2016, RickerEtAl2017} included support for driving the LEDs at two separate wavelength bands (denoted as 2-colors in Figure~\ref{fig:sleds_timeline}. The second, NSLEDS (N Superlattice Infrared Light Emitting Diode System), a 1024 by 1024 sized array\cite{benedict1} doubled the total number of pixels supported. Additionally, these systems demonstrated the beginnings of a modular IR Scene Projection (IRSP) platform\cite{BrowningEtAl2019}. A further increase in size and efficiency occurred in 2018 with the world's first 2048 by 2048 pixel array, HDILED (High Definition Infrared LED). A visual representation of the pixel ratios is shown in Figure~\ref{fig:tcsa_nsleds_hdiled_array_ratio}

    \begin{figure}
        \centering
        \includegraphics[trim=0.5in 0.5in 0.5in 1.5in,width=1.0\textwidth]{fig/sleds_timeline.pdf}
        \caption{IRLED Projector Technology Development Timeline Overview}
        \label{fig:sleds_timeline}
    \end{figure}

    \begin{figure}
        \centering
        \includegraphics[trim=0.5in 0.5in 0.5in 1.5in,width=1.0\textwidth]{fig/tcsa_nsleds_hdiled_array_ratio.pdf}
        \caption{SLEDs Array Pixel Ratios}
        \label{fig:tcsa_nsleds_hdiled_array_ratio}
    \end{figure}

    TCSA represented a novel step forward in terms of IRLED array technology. It incorporated a multiple color pixel design to enable emission in multiple wave-length spectrums, as well as, an increase in the number of analog channels from 4 to 16 to allow for more pixels to be driven at a time. NSLEDS used the same size wafer as a TCSA, but incorporated only a single-color pixel design instead of the multiple color design of the original, which allowed for the pixel resolution to be doubled paving the way toward larger format SLED IRSPs. HDILED combines. The interleaved write process of each array will be discussed in detail in Section~\ref{sec:array_Interleaved_write_process}.

    Figure~\ref{fig:typical_projection} shows a typical projection process utilized within an IRLED system. A scene projector will perform scene generation utilizing a GPU typically. Following this, imagery will be undergo non-uniformity correction by utilizing a NUC table created by analyzing the non-uniformity on a given array. This process compensates for any physical defects that may cause non-linear variation in light emission from different diodes on a given array, thus, allowing for uniform emission across a given spectrum. There are number of different ways this linearization may be performed\cite{BrowningEtAl2016, LandwehrEtAl2017, BarakhshanEtAl2019}, but that is beyond the scope of this work.

    \begin{figure}
        \centering
        \includegraphics[trim=0.5in 0.5in 0.5in 1.5in,width=1.0\textwidth]{fig/typical_projection_system.pdf}
        \caption{Typical IRLED Projection Process}
        \label{fig:typical_projection}
    \end{figure}


    %FIXME: add discussion about the speeds

    %FIXME: add discussion about uses

    %FIXME: add discussion about system layout

\section{Classical Display Protocols}
    \label{sec:classical_display_protocols}

    Classical display protocols such as (DVI\cite{DDWG1999}, HDMI\cite{HDMIForum2018}, and DisplayPort\cite{VESA2016} are commonly used for driving consumer electronic devices. These generally provide a standardized feature-set that is rooted in classical analog video specifications (e.g. VGA, Composite)\cite{NIAnalog} that utilize scan lines\cite{Neal1998}. Scan lines are used to provide video timing information in order to synchronize a display to a given refresh-rate. Each scan line consist of an active video region followed by a horizontal blanking period. After all active video scan lines are displayed, a vertical synchronization region is used to indicate the end of a frame.

    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{fig/display_timing_overview.pdf}
        \caption{Display Protocol Timing Overview}
        \label{fig:display_protocol_timing_overview}
    \end{figure}

    \begin{figure}
        \centering
        \includegraphics[width=0.7\textwidth]{fig/display_timing_line_cross.pdf}
        \caption{Display Protocol Horizontal Signal Cross Section Timing}
        \label{fig:display_protocol_line_cross}
    \end{figure}

    %FIXME add crosssectional blowout chart

    An overview of this is shown in Figure~\ref{fig:display_protocol_timing_overview}. The region shown in green is the pixel data for the active video region of the display. It is of size $H_a\times V_a$ which represents the number of pixels to display, for example, 1920 by 1080 for a HDTV high-definition video mode\cite{MythTVWebsite}. The blanking time regions denote pixel data that is sent but not displayed\footnote{Typically data lines are held low during this period, but somtimes it is used for out-of-band communication to send other information such as audio encoding.}. A scan line consist of pixels made up of $h_a$, the horizontal active size; $h_{fp}$, the horizontal front porch before the pulse signal; $h_{sp}$, the horizontal sync pulse; and $h_{bp}$, the horizontal back porch after the sync pulse. The vertical blanking period makes up multiple scanlines and consist of $v_{fp}$, the vertical front porch before the vsync pulse; $v_{sp}$, the vertical sync pulse; $v_{bp}$, the vertical back porch after the vertical sync pulse. Sync pulses are generally active low, meaning that during active display a sync signal is high as shown in the diagram.

    Figure~\ref{fig:display_protocol_line_cross} shows a closeup view of signal lines during the active region of display for two scan lines. A data enable signal denoted by $enable$ is high during the active region shown in green. Following this, it goes low for a period of time denoted by $h_{fp}+h_{sp}+h_{bp}$. The horizontal sync signal goes low only in the region shown in yellow between the front porch and back porches. This process repeats for all scan lines. Once the last active region pixel is drawn, the enable signal will stop going high during the vertical synchronization period.

    %FIXME: Fix discussion of DP not using fucking backwards compatibility shitty hdmi fucking mode
    %FIXME: Talk about CC in the vertical blanking

    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{fig/display_timing_full_cross.pdf}
        \caption{Display Protocol Full Signal Cross Section Timing}
        \label{fig:display_protocol_full_cross}
    \end{figure}

    Figure~\ref{fig:display_protocol_full_cross} shows a closeup view of signal lines during the transition into the vertical synchronization period. The region donated by $V_a$ indicates the end of the video active region of the display which occurs toward the end of a frame. After the active video region, all data has been drawn to a display. The region denoted by $v_{fp}+v_{sp}+v_{bp}$ is the vertical blanking or vsync period during which no active video data is sent; therefore, data enable denoted by $enable$ is always low during this period. Before the vertical sync pulse period denoted by $v_{sp}$ occurs, a vertical front porch period denoted by $v_{fp}$ occurs. After the vertical sync pulse, a vertical back porch region $v_{bp}$ occurs. Following this the beginning of the next frame occurs as denoted by $v_{a+1}$.
    \begin{figure}
        \centering
        { \Large
            $l_h=h_a+h_{fp}+h_{sp}+h_{bp}$ \vspace{8px} \\
            $l_v=v_a+v_{fp}+v_{sp}+v_{bp}$ \vspace{8px} \\
            $f_f={f_p \over {l_h \cdot l_v}}$ \\
            $p_t={1 \over f_p}$ \vspace{8px} \\
            $f_t={1 \over f_f}$ \vspace{8px}
        }
        \caption{Total Refresh Rate}
        \label{fig:modeline_refresh_rate}
    \end{figure}

    Figure~\ref{fig:modeline_refresh_rate} shows the relationship between between the different regions of a display and the frequency or refresh rate. $l_h$ denotes the scan line size of a display, or total horizontal width, which is made up of the horizontal active and horizontal porch region pixels of a display. $l_v$ denotes the total vertical width of a display, which is made up the vertical active and vertical porch region pixels of a display. Each pixel is sent at a rate denoted by $f_p$, the pixel frequency (also called the pixel clock). $f_f$ denotes the frame frequency or framerate of a display. This is simply the pixel frequency over the total number of pixels (video active and porches) of a display. $p_t$ denotes the time period a single pixel takes to send. $f_t$ denotes the time period for an entire frame.

    %FIXME: example modeline
    To illustrate, let us look at the display modeline generated using the VESA Coordinated Video Timing (CVT) standard shown in Figure~\ref{fig:modeline_example}. This modeline operates a total frame frequency of approximately \mbox{30 Hz}. The pixel clock 79.75, denoted in red, is specified in megahertz. The horizontal pixels, denoted in blue; are the end of horizontal active, the end of horizontal front porch, the end of horizontal sync pulse, and the end of horizontal back porch respectively. The vertical pixels (measured in lines), denoted in green; are the end of vertical active, the end of vertical front porch, the end of vertical sync pulse, and the end of horizontal back porch respectively. The sync pulse polarities, denoted in yellow; indicate whether a given sync pulse is active low or active high. A minus symbol indicates active low and a plus symbol indicates active high. If these numbers are placed into into the formulas shown in Figure~\ref{fig:modeline_refresh_rate} the results shown in Figure~\ref{fig:modeline_refresh_rate_plug} are yielded. The astute reader will note that $l_h$ and $l_v$ are the same as the total pixel size for the given modeline. The pixel period is $\sim12.53 ns$, meaning that each pixel is drawn for the given amount of time. The frame period is $\sim33.33 ms$, meaning that each frame is drawn for that given amount of time.

    \begin{figure}
        \centering
        { \normalsize
        \textbf{``1920x1080\_30.00"} {\color{red}79.75}  {\color{blue} 1920 1976 2168 2416}  {\color{darkgreen}1080 1083 1088 1102} {\color{olive}-hsync +vsync}
        %\vspace{-8px}
        }
        \caption{VESA CVT Generated Modeline}
        \label{fig:modeline_example}
    \end{figure}

    %FIXME: finish this chart
    \begin{figure}
        \centering
        { \Large
            $h_a=1920; h_{fp}=1976-h_a; h_{sp}=2168-h_{fp}; h_{bp}=2416-h_{sp};$ \\
            $v_a=1080; v_{fp}=1083-v_a; v_{sp}=1088-v_{fp}; v_{bp}=1102-v_{sp};$ \\
            $l_h=2416=1920+56+192+248$ \vspace{8px} \\
            $l_v=1102=1080+3+5+14$ \vspace{8px} \\
            $f_p=79.75e6$ \vspace{8px} \\
            $f_f=30.0={f_p \over {l_s \cdot l_c}}$ \\
            $p_t=12.53ns={1 \over f_p}$ \vspace{8px} \\
            $f_t=33.33ms={1 \over f_f}$ \vspace{8px}
        }
        \caption{Computed Refresh Rate for a 30hz CVT Modeline}
        \label{fig:modeline_refresh_rate_plug}
    \end{figure}

    Section~\ref{sec:displays_within_proj_system}, discusses how these protocols are utilized within an IRLED projector system, briefly highlight the limitations, and . %FIXME: finish this paragraph

\section{Display Protocols within an IRLED Project System}
    \label{sec:displays_within_proj_system}
    Projector systems utilize

\section{Array Interleaved Write Process}
    \label{sec:array_Interleaved_write_process}
    As discussed in Section~\ref{sec:classical_display_protocols}, while all current IRSP arrays utilize some display protocol technology that is decoded in order to drive an array's pixels, they may utilize different internal drawing mechanisms for driving the pixels. This section discusses the details of those mechanisms within the NSLEDs and HDILED arrays for conceptual purposes, and while the details may differ for other arrays, the raster write process will be similar.

    The NSLEDs and HDILED arrays are organized into four quadrants as shown in Figure~\ref{fig:tcsa_nsleds_hdiled_quads}. Internally each quadrant has separate internal signaling.

    \begin{figure}
        \centering
        \includegraphics[trim=0in 0.35in 0in 1.5in,width=1.0\textwidth]{fig/tcsa_nsleds_hdiled_quads.pdf}
        \caption[TCSA, NSLEDs, and HIDLED Array Quadrant Layouts]{TCSA, NSLEDs, and HIDLED Array Quadrant Layouts\textsuperscript{a}}
        \vspace{-8px}
        \footnotesize\textsuperscript{a} Not drawn to scale
        \label{fig:tcsa_nsleds_hdiled_quads}
    \end{figure}
